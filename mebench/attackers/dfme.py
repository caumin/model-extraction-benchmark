"""DFME (Data-Free Model Extraction) attack implementation."""

from typing import Dict, Any, Tuple
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from mebench.attackers.base import BaseAttack
from mebench.core.types import QueryBatch, OracleOutput
from mebench.core.state import BenchmarkState
from mebench.models.gan import DCGANGenerator, DFMEGenerator
from mebench.models.substitute_factory import create_substitute


class DFME(BaseAttack):
    """Data-Free Model Extraction via generative adversarial training.

    Algorithm loop (min-max game):
    1. G generates queries: x = G(z) where z ~ N(0, 1)
    2. S learns to mimic V: minimize disagreement (L1 loss)
    3. G learns to maximize disagreement between S and V
    4. Use zeroth-order gradient estimation for G (V is black-box)
    5. Repeat until query budget exhausted

    Hyperparameters (from AGENTS.md):
    - Batch size: 256
    - Student optimizer: SGD, lr=0.1, weight_decay=5e-4
    - Generator optimizer: Adam, lr=5e-4
    - Steps: n_G=1, n_S=5
    - Gradient approx: m=1, epsilon=1e-3
    """

    def __init__(self, config: dict, state: BenchmarkState):
        """Initialize DFME attack.

        Args:
            config: Attack configuration
            state: Global benchmark state
        """
        super().__init__(config, state)

        # Hyperparameters (from AGENTS.md)
        self.batch_size = int(config.get("batch_size", 256))
        self.student_lr = float(config.get("student_lr", 0.1))
        self.student_weight_decay = float(config.get("student_weight_decay", 5e-4))
        # Official DFME repo commonly uses lr_G=1e-4.
        self.generator_lr = float(config.get("generator_lr", 1e-4))
        self.lr_steps = config.get("lr_steps", [0.1, 0.3, 0.5])
        self.lr_scale = float(config.get("lr_scale", 0.3))
        self.n_g_steps = int(config.get("n_g_steps", 1))  # Generator steps
        self.n_s_steps = int(config.get("n_s_steps", 5))  # Student steps
        self.grad_approx_m = int(config.get("grad_approx_m", 1))  # Random directions
        self.grad_approx_epsilon = float(config.get("grad_approx_epsilon", 1e-3))

        # Noise distribution
        self.noise_dim = int(config.get("noise_dim", 100))  # z ~ N(0, 1)

        # Initialize models
        self.student = None  # Will be initialized in propose
        self.generator = None  # Will be initialized in propose
        self.student_optimizer = None
        self.generator_optimizer = None

        # Initialize attack state
        self._initialize_state(state)

    def _initialize_state(self, state: BenchmarkState) -> None:
        """Initialize attack-specific state.

        Args:
            state: Global benchmark state to update
        """
        # Training progress
        state.attack_state["step"] = 0
        state.attack_state["lr_step_index"] = 0

    def _create_student(self, input_shape: tuple) -> nn.Module:
        """Create student model.

        Args:
            input_shape: Input shape (C, H, W)

        Returns:
            Student model
        """
        sub_config = self.state.metadata.get("substitute_config", {})
        arch = sub_config.get("arch", "resnet18-8x")
        num_classes = int(
            self.state.metadata.get("num_classes")
            or self.config.get("num_classes")
            or self.state.metadata.get("dataset_config", {}).get("num_classes", 10)
        )
        input_channels = int(input_shape[0])
        return create_substitute(
            arch=arch,
            num_classes=num_classes,
            input_channels=input_channels,
        )

    def _create_generator(self) -> nn.Module:
        """Create generator model."""
        gen_type = str(self.config.get("generator_type", "dfme")).lower()
        input_shape = self.state.metadata.get("input_shape", (3, 32, 32))
        output_size = int(input_shape[1])
        output_channels = int(self.config.get("output_channels", input_shape[0]))
        base_channels = int(self.config.get("base_channels", 128))
        if gen_type in {"dfme", "upsample_conv"}:
            return DFMEGenerator(
                noise_dim=self.noise_dim,
                output_channels=output_channels,
                base_channels=base_channels,
                output_size=output_size,
            )
        return DCGANGenerator(
            noise_dim=self.noise_dim,
            output_channels=output_channels,
            base_channels=int(self.config.get("base_channels", 64)),
            num_classes=None,
            output_size=output_size,
        )

    def propose(self, k: int, state: BenchmarkState) -> QueryBatch:
        """Propose k synthetic queries generated by G.

        Args:
            k: Number of queries to propose
            state: Current benchmark state

        Returns:
            QueryBatch with k synthetic queries
        """
         # Initialize models if first time
        device = state.metadata.get("device", "cpu")
        if self.generator is None:
            self.generator = self._create_generator().to(device)
            self.generator_optimizer = optim.Adam(
                self.generator.parameters(), lr=self.generator_lr
            )
        if self.student is None:
            self.student = self._create_student(state.metadata.get("input_shape", (3, 32, 32))).to(device)
            sub_config = state.metadata.get("substitute_config", {})
            opt_params = sub_config.get("optimizer", {})
            self.student_optimizer = optim.SGD(
                self.student.parameters(),
                lr=float(opt_params.get("lr", self.student_lr)),
                momentum=float(opt_params.get("momentum", 0.9)),
                weight_decay=float(opt_params.get("weight_decay", self.student_weight_decay)),
            )

        if self.student is None:
            self.student = self._create_student(state.metadata.get("input_shape", (3, 32, 32))).to(
                state.metadata.get("device", "cpu")
            )
            self.student_optimizer = optim.SGD(
                self.student.parameters(),
                lr=self.student_lr,
                weight_decay=self.student_weight_decay,
            )

        device = state.metadata.get("device", "cpu")
        if state.budget_remaining is not None and state.budget_remaining > 0:
            k = min(int(k), int(state.budget_remaining))
        k = int(k)
        if k <= 0:
            raise ValueError("DFME propose(k) requires k>0")

        # Contract: propose(k) must return exactly k images.
        remaining = k
        z_list = []
        m_list = []
        x_parts = []
        directions_list = []

        # Probe output shape once.
        with torch.no_grad():
            pre_tanh_probe, _ = self.generator(torch.randn(1, self.noise_dim, device=device), return_pre_tanh=True)
            x_shape = pre_tanh_probe.shape[1:]

        while remaining > 0:
            m_eff = 0
            if remaining > 1:
                m_eff = min(int(self.grad_approx_m), remaining - 1)
            z = torch.randn(1, self.noise_dim, device=device)
            with torch.no_grad():
                pre_tanh, x_base = self.generator(z, return_pre_tanh=True)
            x_parts.append(x_base)
            z_list.append(z)
            m_list.append(m_eff)

            if m_eff > 0:
                dirs = torch.randn(1, m_eff, *x_shape, device=device)
                norm = dirs.view(1, m_eff, -1).norm(dim=2, keepdim=True) + 1e-12
                dirs = dirs / norm.view(1, m_eff, 1, 1, 1)
                pre_tanh_pert = pre_tanh.unsqueeze(1) + self.grad_approx_epsilon * dirs
                pre_tanh_pert = pre_tanh_pert.view(m_eff, *x_shape)
                x_pert = torch.tanh(pre_tanh_pert)
                x_parts.append(x_pert)
                directions_list.append(dirs)
            else:
                directions_list.append(torch.zeros(1, 0, *x_shape, device=device))

            remaining -= 1 + m_eff

        x_all = torch.cat(x_parts, dim=0)
        if x_all.size(0) != k:
            raise RuntimeError(f"DFME propose(k) packing bug: expected {k}, got {x_all.size(0)}")

        max_m = int(self.grad_approx_m)
        n_bases = len(z_list)
        directions = torch.zeros(n_bases, max_m, *x_shape, device=device)
        m_per_base = torch.zeros(n_bases, dtype=torch.long, device=device)
        for i, m_eff in enumerate(m_list):
            m_per_base[i] = int(m_eff)
            if m_eff > 0:
                directions[i, :m_eff] = directions_list[i][0]

        meta = {
            "generator_step": state.attack_state["step"],
            "synthetic": True,
            "z": torch.cat(z_list, dim=0).detach().cpu(),
            "directions": directions.detach().cpu(),
            "m_per_base": m_per_base.detach().cpu(),
        }

        return QueryBatch(x=x_all, meta=meta)

    def observe(
        self,
        query_batch: QueryBatch,
        oracle_output: OracleOutput,
        state: BenchmarkState,
    ) -> None:
        """Update G and S based on oracle response.

        Performs one training iteration:
        1. G-step (n_G times): Maximize disagreement using gradient estimation
        2. S-step (n_S times): Minimize L1 loss

        Args:
            query_batch: The query batch that was sent
            oracle_output: Oracle response
            state: Current benchmark state
        """
        x_all = query_batch.x
        device = x_all.device
        z_cpu = query_batch.meta.get("z")
        directions_cpu = query_batch.meta.get("directions")
        m_per_base_cpu = query_batch.meta.get("m_per_base")

        if z_cpu is None or directions_cpu is None or m_per_base_cpu is None:
            return

        z = z_cpu.to(device)
        directions = directions_cpu.to(device)
        m_per_base = m_per_base_cpu.to(device)

        bases = []
        perturbed = []
        cursor = 0
        for i in range(int(m_per_base.numel())):
            m_eff = int(m_per_base[i].item())
            bases.append(x_all[cursor : cursor + 1])
            cursor += 1
            if m_eff > 0:
                perturbed.append(x_all[cursor : cursor + m_eff])
                cursor += m_eff
        if cursor != x_all.size(0):
            return
        x_base = torch.cat(bases, dim=0)
        x_perturbed = torch.cat(perturbed, dim=0) if perturbed else torch.empty(0, *x_all.shape[1:], device=device)

        # Convert oracle output to logits if needed
        if oracle_output.kind == "soft_prob":
            log_probs = torch.log(oracle_output.y.to(device) + 1e-6)
            victim_logits = log_probs - log_probs.mean(dim=1, keepdim=True)
        else:
            num_classes = int(
                self.state.metadata.get("num_classes")
                or self.config.get("num_classes")
                or self.state.metadata.get("dataset_config", {}).get("num_classes", 10)
            )
            victim_logits = torch.zeros(oracle_output.y.shape[0], num_classes).to(device)
            victim_logits.scatter_(1, oracle_output.y.to(device).unsqueeze(1), 1.0)

        # Match victim outputs to our unpacking.
        victim_base = []
        victim_perturbed = []
        cursor = 0
        for i in range(int(m_per_base.numel())):
            m_eff = int(m_per_base[i].item())
            victim_base.append(victim_logits[cursor : cursor + 1])
            cursor += 1
            if m_eff > 0:
                victim_perturbed.append(victim_logits[cursor : cursor + m_eff])
                cursor += m_eff
        victim_base = torch.cat(victim_base, dim=0)
        victim_perturbed = (
            torch.cat(victim_perturbed, dim=0)
            if victim_perturbed
            else torch.empty(0, victim_logits.size(1), device=device)
        )

        # G-step: approximate gradient in input space then backprop through G
        for _ in range(self.n_g_steps):
            self.generator_optimizer.zero_grad()
            gen_out = self.generator(z, return_pre_tanh=True)
            if isinstance(gen_out, tuple):
                pre_tanh_base, x_base_grad = gen_out
            else:
                pre_tanh_base = gen_out
                x_base_grad = gen_out
            student_base = self.student(x_base_grad)
            loss_base = torch.mean(torch.abs(student_base - victim_base), dim=1)

            if x_perturbed.numel() > 0:
                student_pert = self.student(x_perturbed.detach())
                loss_pert_all = torch.mean(torch.abs(student_pert - victim_perturbed), dim=1)
            else:
                loss_pert_all = torch.empty(0, device=device)

            grad_est = torch.zeros_like(pre_tanh_base)
            cursor_pert = 0
            for i in range(pre_tanh_base.size(0)):
                m_eff = int(m_per_base[i].item())
                if m_eff <= 0:
                    continue
                loss_i = loss_base[i]
                loss_p = loss_pert_all[cursor_pert : cursor_pert + m_eff]
                dirs = directions[i, :m_eff].view(m_eff, -1)
                loss_diff = (loss_p - loss_i) / float(self.grad_approx_epsilon)
                g = torch.sum(loss_diff.view(m_eff, 1) * dirs, dim=0)
                grad_est[i] = g.view_as(grad_est[i])
                cursor_pert += m_eff

            # Gradient Ascent: Negate gradient to maximize disagreement
            pre_tanh_base.backward(-grad_est)
            self.generator_optimizer.step()

        # S-step: Minimize disagreement using base queries
        victim_config = state.metadata.get("victim_config", {})
        normalization = victim_config.get("normalization")
        if normalization is None:
            normalization = {"mean": [0.0], "std": [1.0]}
            
        norm_mean = torch.tensor(normalization["mean"]).view(1, -1, 1, 1).to(device)
        norm_std = torch.tensor(normalization["std"]).view(1, -1, 1, 1).to(device)

        def _normalize_dfme(x):
            # DFME generates in [-1, 1]. Map to [0, 1] then victim norm.
            x_01 = x * 0.5 + 0.5
            return (x_01 - norm_mean) / norm_std

        for _ in range(self.n_s_steps):
            self.student_optimizer.zero_grad()
            student_logits = self.student(_normalize_dfme(x_base.detach()))
            loss = torch.mean(torch.abs(student_logits - victim_base))
            loss.backward()
            self.student_optimizer.step()

        # Update step counter
        state.attack_state["step"] += 1

        self._maybe_step_lr(state)

        # Store trained student in state for Track B evaluation
        state.attack_state["substitute"] = self.student

    def _maybe_step_lr(self, state: BenchmarkState) -> None:
        if self.student_optimizer is None or self.generator_optimizer is None:
            return

        max_budget = state.metadata.get("max_budget")
        if max_budget is None:
            return

        step_index = int(state.attack_state.get("lr_step_index", 0))
        if step_index >= len(self.lr_steps):
            return

        thresholds = [int(step * max_budget) for step in self.lr_steps]
        if state.query_count < thresholds[step_index]:
            return

        for optimizer in [self.student_optimizer, self.generator_optimizer]:
            for param_group in optimizer.param_groups:
                param_group["lr"] *= self.lr_scale

        state.attack_state["lr_step_index"] = step_index + 1

    def _approximate_generator_gradient(
        self, x: torch.Tensor, victim_logits: torch.Tensor, state: BenchmarkState
    ) -> list:
        """Approximate generator gradient using zeroth-order estimation.

        Args:
            x: Generated samples
            victim_logits: Victim model logits
            state: Current benchmark state

        Returns:
            List of gradients for each parameter
        """
        # Placeholder: Forward difference estimation
        # For random directions d_i, compute:
        # grad â‰ˆ (L(x + epsilon*d) - L(x)) / epsilon * d

        epsilon = self.grad_approx_epsilon
        m = self.grad_approx_m

        # Compute baseline loss
        student_logits = self.student(x)
        baseline_loss = torch.mean(torch.abs(student_logits - victim_logits))

        gradients = []
        for param in self.generator.parameters():
            # Random directions
            directions = [torch.randn_like(param) for _ in range(m)]

            # Estimate gradient
            grad_est = torch.zeros_like(param)
            for d in directions:
                # Perturb parameters
                original_data = param.data.clone()
                param.data = param.data + epsilon * d

                # Compute perturbed loss
                student_logits = self.student(x)
                perturbed_loss = torch.mean(torch.abs(student_logits - victim_logits))

                # Finite difference
                grad_est += (perturbed_loss - baseline_loss) / epsilon * d

                # Restore original parameters
                param.data = original_data

            # Average over directions
            grad_est = grad_est / m
            gradients.append(grad_est)

        return gradients
